{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1294950f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX_MODEL_PATH = /home/surya/Desktop/damaged_car_parts_detection/runs/detect/train3/weights/best.onnx\n",
      "MODEL_NAME = best\n",
      "WORKING_DIR = /tmp/surya/mltk\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from mltk.utils.path import create_tempdir\n",
    "\n",
    "\n",
    "# This contains the path to the pre-trained model in ONNX model format\n",
    "# For this tutorial, we use the one downloaded from above\n",
    "# Update this path to point to your specific model if necessary\n",
    "ONNX_MODEL_PATH = '/home/surya/Desktop/damaged_car_parts_detection/runs/detect/train3/weights/best.onnx'\n",
    "\n",
    "\n",
    "WORKING_DIR = create_tempdir('/home/surya/Desktop/damaged_car_parts_detection/model_onnx_to_tflite')\n",
    "\n",
    "\n",
    "\n",
    "assert os.path.exists(ONNX_MODEL_PATH), f'The provided ONNX_MODEL_PATH does not exist at: {ONNX_MODEL_PATH}'\n",
    "os.makedirs(WORKING_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# Use the filename for the model's name\n",
    "MODEL_NAME = os.path.basename(ONNX_MODEL_PATH)[:-len('.onnx')]\n",
    "\n",
    "\n",
    "print(f'ONNX_MODEL_PATH = {ONNX_MODEL_PATH}')\n",
    "print(f'MODEL_NAME = {MODEL_NAME}')\n",
    "print(f'WORKING_DIR = {WORKING_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec1d5ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# This is the class label order specified by the dataset\n",
    "# y_test contains a list of integers that correspond to the indices in this class_labels list\n",
    "       \n",
    "class_labels = ['damaged door', 'damaged window', 'damaged headlight', 'damaged mirror', 'dent', 'damaged hood', 'damaged bumper', 'damaged wind shield']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c582d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def load_data(data_dir):\n",
    "    \"\"\"Loads custom dataset and preprocesses it to match CIFAR-10.\n",
    "    Assumes the images are stored in the directory structure\n",
    "    `data_dir/class_name/image_name.jpg`.\n",
    "    Returns:\n",
    "        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
    "    \"\"\"\n",
    "    classes = sorted(os.listdir(data_dir))\n",
    "\n",
    "    # Count the number of samples in the training and test sets\n",
    "    num_train_samples = 0\n",
    "    num_test_samples = 0\n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        num_images = len(os.listdir(class_dir))\n",
    "        num_train = int(num_images * 0.8)\n",
    "        num_test = num_images - num_train\n",
    "        num_train_samples += num_train\n",
    "        num_test_samples += num_test\n",
    "\n",
    "    # Initialize the arrays to hold the data\n",
    "    x_train = np.zeros((num_train_samples, 32, 32, 3), dtype='float32')\n",
    "    y_train = np.zeros((num_train_samples,), dtype='uint8')\n",
    "    x_test = np.zeros((num_test_samples, 32, 32, 3), dtype='float32')\n",
    "    y_test = np.zeros((num_test_samples,), dtype='uint8')\n",
    "\n",
    "    # Load the data from each class\n",
    "    train_index = 0\n",
    "    test_index = 0\n",
    "    for class_index, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        image_names = os.listdir(class_dir)\n",
    "        np.random.shuffle(image_names)\n",
    "        num_images = len(image_names)\n",
    "        num_train = int(num_images * 0.8)\n",
    "        num_test = num_images - num_train\n",
    "        for i in range(num_train):\n",
    "            image_name = image_names[i]\n",
    "            image_path = os.path.join(class_dir, image_name)\n",
    "            img = Image.open(image_path)\n",
    "            img = img.resize((32, 32))\n",
    "            x_train[train_index] = np.array(img, dtype='float32') / 255.0\n",
    "            y_train[train_index] = class_index\n",
    "            train_index += 1\n",
    "        for i in range(num_test):\n",
    "            image_name = image_names[num_train + i]\n",
    "            image_path = os.path.join(class_dir, image_name)\n",
    "            img = Image.open(image_path)\n",
    "            img = img.resize((32, 32))\n",
    "            x_test[test_index] = np.array(img, dtype='float32') / 255.0\n",
    "            y_test[test_index] = class_index\n",
    "            test_index += 1\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a68124b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='test_images'\n",
    "(_, _), (x_test, y_test) = load_data(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b924f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.astype('float32')\n",
    "# Scale the samples by 255 since that's the preprocessing\n",
    "# used during model training\n",
    "x_test = x_test/255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8e5f3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test.shape = (97, 32, 32, 3)\n",
      "y_test.shape = (97,)\n"
     ]
    }
   ],
   "source": [
    "print(f'x_test.shape = {x_test.shape}')\n",
    "print(f'y_test.shape = {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4db58fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_class_labels = ['damaged door', 'damaged window', 'damaged headlight', 'damaged mirror', 'dent', 'damaged hood', 'damaged bumper', 'damaged wind shield']\n",
    "CLASS_ID_MAPPING = {\n",
    "0: 0, \n",
    "1: 1, \n",
    "2: 2, \n",
    "3: 3 ,\n",
    "4: 4,\n",
    "5: 5,\n",
    "6: 6,\n",
    "7: 7\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af01136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12a735fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, y in enumerate(y_test):\n",
    "    y_test[i] = CLASS_ID_MAPPING[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1913f542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: (64, 21, 5)\n",
      "Reshaped tensor shape: (1, 4, 16, 21, 5)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a tensor with 1344 elements\n",
    "tensor_1344 = tf.ones((64, 21, 5))\n",
    "print(\"Original tensor shape:\", tensor_1344.shape)\n",
    "\n",
    "# Reshape tensor with 1344 elements to shape [1,4,16,21,5]\n",
    "new_shape = (1, 4, 16, 21, 5)\n",
    "\n",
    "# Add missing dimensions\n",
    "missing_dims = len(new_shape) - len(tensor_1344.shape)\n",
    "if missing_dims > 0:\n",
    "    tensor_1344 = tf.reshape(tensor_1344, tuple(tensor_1344.shape) + (1,) * missing_dims)\n",
    "\n",
    "# Reshape tensor to new shape\n",
    "reshaped_tensor = tf.reshape(tensor_1344, new_shape)\n",
    "print(\"Reshaped tensor shape:\", reshaped_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12202528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.shape = (97, 8)\n",
      "Generating model predictions for each test sample using /home/surya/Desktop/damaged_car_parts_detection/runs/detect/train3/weights/best.onnx\n",
      "Be patient, this may take awhile ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/surya/.local/lib/python3.10/site-packages/onnx_tf/backend_tf_module.py\", line 99, in __call__  *\n        output_ops = self.backend._onnx_node_to_tensorflow_op(onnx_node,\n    File \"/home/surya/.local/lib/python3.10/site-packages/onnx_tf/backend.py\", line 347, in _onnx_node_to_tensorflow_op  *\n        return handler.handle(node, tensor_dict=tensor_dict, strict=strict)\n    File \"/home/surya/.local/lib/python3.10/site-packages/onnx_tf/handlers/handler.py\", line 59, in handle  *\n        return ver_handle(node, **kwargs)\n    File \"/home/surya/.local/lib/python3.10/site-packages/onnx_tf/handlers/backend/reshape.py\", line 64, in version_14  *\n        return cls._common(node, **kwargs)\n    File \"/home/surya/.local/lib/python3.10/site-packages/onnx_tf/handlers/backend/reshape.py\", line 44, in _common  *\n        cls.make_tensor_from_onnx_node(node,\n    File \"/home/surya/.local/lib/python3.10/site-packages/onnx_tf/handlers/backend_handler.py\", line 157, in make_tensor_from_onnx_node  *\n        return cls._run_tf_func(tf_func, inputs, attrs)\n    File \"/home/surya/.local/lib/python3.10/site-packages/onnx_tf/handlers/backend_handler.py\", line 237, in _run_tf_func  *\n        return tf_func(**kwargs)\n\n    ValueError: Cannot reshape a tensor with 1344 elements to shape [1,4,16,8400] (537600 elements) for '{{node onnx_tf_prefix_/model.22/dfl/Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT64](onnx_tf_prefix_/model.22/Split, add_66)' with input shapes: [1,64,21], [4] and with input tensors computed as partial shapes: input[1] = [1,4,16,8400].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(x, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Run inference on the sample\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_rep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Save the model prediction\u001b[39;00m\n\u001b[1;32m     30\u001b[0m y_pred[i] \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/onnx_tf/backend_rep.py:107\u001b[0m, in \u001b[0;36mTensorflowRep.run\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     input_dict[k] \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant(v)\n\u001b[0;32m--> 107\u001b[0m output_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m o_values \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m o_name \u001b[38;5;129;01min\u001b[39;00m output_values:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filengsawc_z.py:30\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m onnx_node \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monnx_node\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m curr_node_output_map \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurr_node_output_map\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterate_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mdict\u001b[39m), (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_4\u001b[39m():\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filengsawc_z.py:23\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__.<locals>.loop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     21\u001b[0m node \u001b[38;5;241m=\u001b[39m itr\n\u001b[1;32m     22\u001b[0m onnx_node \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(OnnxNode), (ag__\u001b[38;5;241m.\u001b[39mld(node),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 23\u001b[0m output_ops \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_onnx_node_to_tensorflow_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnx_node\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandlers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m curr_node_output_map \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mdict\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mzip\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(onnx_node)\u001b[38;5;241m.\u001b[39moutputs, ag__\u001b[38;5;241m.\u001b[39mld(output_ops)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     25\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tensor_dict)\u001b[38;5;241m.\u001b[39mupdate, (ag__\u001b[38;5;241m.\u001b[39mld(curr_node_output_map),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file0mrzhxdh.py:62\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___onnx_node_to_tensorflow_op\u001b[0;34m(cls, node, tensor_dict, handlers, opset, strict)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     61\u001b[0m handler \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhandler\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandlers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdo_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretval_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_2\u001b[39m():\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file0mrzhxdh.py:56\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___onnx_node_to_tensorflow_op.<locals>.if_body_1\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m retval_, do_return\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdo_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretval_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file0mrzhxdh.py:48\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___onnx_node_to_tensorflow_op.<locals>.if_body_1.<locals>.if_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(handler)\u001b[38;5;241m.\u001b[39mhandle, (ag__\u001b[38;5;241m.\u001b[39mld(node),), \u001b[38;5;28mdict\u001b[39m(tensor_dict\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(tensor_dict), strict\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(strict)), fscope)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filev9qo8wor.py:41\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__handle\u001b[0;34m(cls, node, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m retval_, do_return\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(BackendIsNotSupposedToImplementIt), (ag__\u001b[38;5;241m.\u001b[39mconverted_call(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m version \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is not implemented.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat, (ag__\u001b[38;5;241m.\u001b[39mld(node)\u001b[38;5;241m.\u001b[39mop_type, ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mcls\u001b[39m)\u001b[38;5;241m.\u001b[39mSINCE_VERSION), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 41\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mver_handle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdo_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretval_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filev9qo8wor.py:33\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__handle.<locals>.if_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(ver_handle), (ag__\u001b[38;5;241m.\u001b[39mld(node),), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filepuulhjg6.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__version\u001b[0;34m(cls, node, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mcls\u001b[39m)\u001b[38;5;241m.\u001b[39m_common, (ag__\u001b[38;5;241m.\u001b[39mld(node),), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filegt9ohkqj.py:99\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___common\u001b[0;34m(cls, node, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m copied_shape \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcopied_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     98\u001b[0m indices_scattered \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindices_scattered\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 99\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo_return\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdo_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretval_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filegt9ohkqj.py:84\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___common.<locals>.if_body_3\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m [ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mcls\u001b[39m)\u001b[38;5;241m.\u001b[39mmake_tensor_from_onnx_node, (ag__\u001b[38;5;241m.\u001b[39mld(node),), \u001b[38;5;28mdict\u001b[39m(inputs\u001b[38;5;241m=\u001b[39m[ag__\u001b[38;5;241m.\u001b[39mld(tensor), ag__\u001b[38;5;241m.\u001b[39mld(copied_shape)], attrs\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(attrs), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope)]\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filel9kzzh9o.py:160\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__make_tensor_from_onnx_node\u001b[0;34m(cls, node, tf_func, inputs, attrs, name, c_first_cuda_only, c_last_only, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mnot_(do_return), if_body_6, else_body_6, get_state_6, set_state_6, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdo_return\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretval_\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 160\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_first_cuda_only\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_7\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_7\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_7\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_7\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdo_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretval_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filel9kzzh9o.py:159\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__make_tensor_from_onnx_node.<locals>.else_body_7\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m retval_, do_return\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo_return\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_6\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_6\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_6\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_6\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdo_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretval_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filel9kzzh9o.py:151\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__make_tensor_from_onnx_node.<locals>.else_body_7.<locals>.if_body_6\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mcls\u001b[39m)\u001b[38;5;241m.\u001b[39m_run_tf_func, (ag__\u001b[38;5;241m.\u001b[39mld(tf_func), ag__\u001b[38;5;241m.\u001b[39mld(inputs), ag__\u001b[38;5;241m.\u001b[39mld(attrs)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileooxa81a8.py:100\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___run_tf_func\u001b[0;34m(cls, tf_func, inputs, attrs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf_func), (), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/surya/.local/lib/python3.10/site-packages/onnx_tf/backend_tf_module.py\", line 99, in __call__  *\n        output_ops = self.backend._onnx_node_to_tensorflow_op(onnx_node,\n    File \"/home/surya/.local/lib/python3.10/site-packages/onnx_tf/backend.py\", line 347, in _onnx_node_to_tensorflow_op  *\n        return handler.handle(node, tensor_dict=tensor_dict, strict=strict)\n    File \"/home/surya/.local/lib/python3.10/site-packages/onnx_tf/handlers/handler.py\", line 59, in handle  *\n        return ver_handle(node, **kwargs)\n    File \"/home/surya/.local/lib/python3.10/site-packages/onnx_tf/handlers/backend/reshape.py\", line 64, in version_14  *\n        return cls._common(node, **kwargs)\n    File \"/home/surya/.local/lib/python3.10/site-packages/onnx_tf/handlers/backend/reshape.py\", line 44, in _common  *\n        cls.make_tensor_from_onnx_node(node,\n    File \"/home/surya/.local/lib/python3.10/site-packages/onnx_tf/handlers/backend_handler.py\", line 157, in make_tensor_from_onnx_node  *\n        return cls._run_tf_func(tf_func, inputs, attrs)\n    File \"/home/surya/.local/lib/python3.10/site-packages/onnx_tf/handlers/backend_handler.py\", line 237, in _run_tf_func  *\n        return tf_func(**kwargs)\n\n    ValueError: Cannot reshape a tensor with 1344 elements to shape [1,4,16,8400] (537600 elements) for '{{node onnx_tf_prefix_/model.22/dfl/Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT64](onnx_tf_prefix_/model.22/Split, add_66)' with input shapes: [1,64,21], [4] and with input tensors computed as partial shapes: input[1] = [1,4,16,8400].\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(ONNX_MODEL_PATH)\n",
    "tf_rep = prepare(onnx_model)\n",
    "\n",
    "n_samples = min(len(x_test), 1000) # Let's evaluate up to 1000 samples\n",
    "n_classes = len(mapped_class_labels)\n",
    "\n",
    "# Allocate an array to hold the model predictions\n",
    "y_pred = np.empty((n_samples, n_classes), dtype=np.float32)\n",
    "print(f'y_pred.shape = {y_pred.shape}')\n",
    "\n",
    "# The dataset uses the format: NHWC (i.e. channels last)\n",
    "# However, the ONNX model expects NCHW (i.e. channels first)\n",
    "# So transpose the x_test data to be in NCHW format\n",
    "x_test_channels_first = x_test.transpose(0, 3, 1, 2)\n",
    "\n",
    "# Iterate through each test sample\n",
    "print(f'Generating model predictions for each test sample using {ONNX_MODEL_PATH}')\n",
    "print('Be patient, this may take awhile ...')\n",
    "for i, x in enumerate(x_test_channels_first[:n_samples]):\n",
    "    # Add the N dimension to the individual sample\n",
    "    # e.g. CHW -> NCHW\n",
    "    x = np.expand_dims(x, 0)\n",
    "    # Run inference on the sample\n",
    "    outputs = tf_rep.run(x)\n",
    "    # Save the model prediction\n",
    "    y_pred[i] = outputs[0]\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2bb5b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR:0@1.317] global onnx_importer.cpp:1051 handleNode DNN/ONNX: ERROR during processing node with 2 inputs and 1 outputs: [Reshape]:(onnx_node!/model.22/dfl/Reshape) from domain='ai.onnx'\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /io/opencv/modules/dnn/src/onnx/onnx_importer.cpp:1073: error: (-2:Unspecified error) in function 'handleNode'\n> Node [Reshape@ai.onnx]:(onnx_node!/model.22/dfl/Reshape) parse error: OpenCV(4.7.0) /io/opencv/modules/dnn/src/layers/reshape_layer.cpp:109: error: (-215:Assertion failed) total(srcShape, srcRange.start, srcRange.end) == maskTotal in function 'computeShapeByReshapeMask'\n> ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load Model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadNet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/surya/Desktop/damaged_car_parts_detection/runs/detect/train3/weights/best.onnx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/dnn/src/onnx/onnx_importer.cpp:1073: error: (-2:Unspecified error) in function 'handleNode'\n> Node [Reshape@ai.onnx]:(onnx_node!/model.22/dfl/Reshape) parse error: OpenCV(4.7.0) /io/opencv/modules/dnn/src/layers/reshape_layer.cpp:109: error: (-215:Assertion failed) total(srcShape, srcRange.start, srcRange.end) == maskTotal in function 'computeShapeByReshapeMask'\n> "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load Model\n",
    "net = cv2.dnn.readNet('/home/surya/Desktop/damaged_car_parts_detection/runs/detect/train3/weights/best.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480bc85d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
